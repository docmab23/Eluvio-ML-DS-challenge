{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Xgboost_Bag_of_words.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "I43RxEVmqLMc"
      },
      "source": [
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xg\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "\n",
        "\n",
        "url = 'https://drive.google.com/file/d/15X00ZWBjla7qGOIW33j8865QdF89IyAk/view?usp=sharing'\n",
        "path = 'https://drive.google.com/uc?export=download&id='+url.split('/')[-2]\n",
        "df = pd.read_csv(path)\n",
        "titles = df['title'][0:10000] # Taken only 10000 samples as Colab was Crashing a lot\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "\n"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjnL71Qdukz3"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import heapq\n",
        "tokens = [word_tokenize(t) for t in titles]\n",
        "stop_words = set(stopwords.words('english')) # Get rid of Stopwords\n",
        "\n"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1pMwCXwBdi5"
      },
      "source": [
        "word2count = {}      # Create Bag of words model for the text data\n",
        "for data in titles:\n",
        "    words = nltk.word_tokenize(data)\n",
        "    for t in words:\n",
        "      if t.lower() in stop_words:\n",
        "       words.remove(t)\n",
        "    for word in words:\n",
        "        if word not in word2count.keys():\n",
        "            word2count[word] = 1\n",
        "        else:\n",
        "            word2count[word] += 1\n",
        "freq_words = heapq.nlargest(200, word2count, key=word2count.get)\n",
        "\n",
        "X = []\n",
        "for data in titles:\n",
        "    vector = []\n",
        "    for word in freq_words:\n",
        "        if word in nltk.word_tokenize(data):\n",
        "            vector.append(1)\n",
        "        else:\n",
        "            vector.append(0)\n",
        "    X.append(vector)\n",
        "X = np.asarray(X)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpX1rB7qWUl-",
        "outputId": "1b5f99e1-284b-4944-8c67-9dbbd12760c3"
      },
      "source": [
        "Y_ = df.up_votes[0:10000] \n",
        "#Train a Xgboost model to predict upvotes \n",
        "train_X, test_X, train_y, test_y = train_test_split(X, Y_, test_size = 0.15)\n",
        "  \n",
        "xgb_r = xg.XGBRegressor(n_estimators = 60 , max_depth =15)\n",
        "  \n",
        "xgb_r.fit(train_X, train_y)\n"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[11:26:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
              "             max_depth=15, min_child_weight=1, missing=None, n_estimators=60,\n",
              "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
              "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "             silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trS6lU-sZuMs",
        "outputId": "3f333e7d-b7c3-44be-8ca5-ae94f468f699"
      },
      "source": [
        "pred = xgb_r.predict(test_X)\n",
        "  \n",
        "# RMSE Computation\n",
        "rmse = np.sqrt(MSE(test_y, pred))\n",
        "print(\"RMSE : % f\" %(rmse))"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE :  37.838332\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtqMkmMUb3oq"
      },
      "source": [
        "So this is not a great model , probably textual information cannot be a great predictor for the number of Upvotes\n"
      ]
    }
  ]
}
